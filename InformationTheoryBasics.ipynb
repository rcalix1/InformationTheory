{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ec97de",
   "metadata": {},
   "source": [
    "## Information Theory Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf18c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from mxnet import np\n",
    "from mxnet.metric import NegativeLogLikelihood\n",
    "from mxnet.ndarray import nansum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ccb3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def self_information(p):\n",
    "    return -np.log2(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68478e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "self_information(1 / 64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed55ec",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca073b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy(p):\n",
    "    entropy = - p * np.log2(p)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(entropy.as_nd_ndarray())\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52df1ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.6854753]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(np.array([0.1, 0.5, 0.1, 0.3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4245ce",
   "metadata": {},
   "source": [
    "\n",
    "## Joint Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ba91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def joint_entropy(p_xy):\n",
    "    joint_ent = -p_xy * np.log2(p_xy)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(joint_ent.as_nd_ndarray())\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac133aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1.6854753]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_entropy(np.array([[0.1, 0.5], [0.1, 0.3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b2416",
   "metadata": {},
   "source": [
    "## Conditional Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6efe5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conditional_entropy(p_xy, p_x):\n",
    "    p_y_given_x = p_xy/p_x\n",
    "    cond_ent = -p_xy * np.log2(p_y_given_x)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(cond_ent.as_nd_ndarray())\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc19e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.8635472]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conditional_entropy(np.array([[0.1, 0.5], [0.2, 0.3]]), np.array([0.2, 0.8]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f642306",
   "metadata": {},
   "source": [
    "\n",
    "## Mutual Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac9ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutual_information(p_xy, p_x, p_y):\n",
    "    p = p_xy / (p_x * p_y)\n",
    "    mutual = p_xy * np.log2(p)\n",
    "    # Operator `nansum` will sum up the non-nan number\n",
    "    out = nansum(mutual.as_nd_ndarray())\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7022fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.7194603]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_information(np.array([[0.1, 0.5], [0.1, 0.3]]),\n",
    "                   np.array([0.2, 0.8]), np.array([[0.75, 0.25]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3777bd",
   "metadata": {},
   "source": [
    "\n",
    "## Kullbackâ€“Leibler Divergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6318da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kl_divergence(p, q):\n",
    "    kl = p * np.log2(p / q)\n",
    "    out = nansum(kl.as_nd_ndarray())\n",
    "    return out.abs().asscalar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b76ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.seed(1)\n",
    "\n",
    "nd_len = 10000\n",
    "p = np.random.normal(loc=0, scale=1, size=(nd_len, ))\n",
    "q1 = np.random.normal(loc=-1, scale=1, size=(nd_len, ))\n",
    "q2 = np.random.normal(loc=1, scale=1, size=(nd_len, ))\n",
    "\n",
    "p = np.array(sorted(p.asnumpy()))\n",
    "q1 = np.array(sorted(q1.asnumpy()))\n",
    "q2 = np.array(sorted(q2.asnumpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "731a6809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8470.638, 8664.998, 2.268492904612395)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kl_pq1 = kl_divergence(p, q1)\n",
    "kl_pq2 = kl_divergence(p, q2)\n",
    "similar_percentage = abs(kl_pq1 - kl_pq2) / ((kl_pq1 + kl_pq2) / 2) * 100\n",
    "\n",
    "kl_pq1, kl_pq2, similar_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f3815dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13536.835, 43.88680093791528)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kl_q2p = kl_divergence(q2, p)\n",
    "differ_percentage = abs(kl_q2p - kl_pq2) / ((kl_q2p + kl_pq2) / 2) * 100\n",
    "\n",
    "kl_q2p, differ_percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3efe9a",
   "metadata": {},
   "source": [
    "\n",
    "## Cross-Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39cd34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "    ce = -np.log(y_hat[range(len(y_hat)), y])\n",
    "    return ce.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40713246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.94856)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels = np.array([0, 2])\n",
    "preds = np.array([[0.3, 0.6, 0.1], [0.2, 0.3, 0.5]])\n",
    "\n",
    "cross_entropy(preds, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d09dcd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nll-loss', 0.9485599994659424)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nll_loss = NegativeLogLikelihood()\n",
    "nll_loss.update(labels.as_nd_ndarray(), preds.as_nd_ndarray())\n",
    "nll_loss.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dad1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf37231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbd996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff151f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
