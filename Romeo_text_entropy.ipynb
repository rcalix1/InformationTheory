{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930dbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import codecs\n",
    "import random\n",
    "import re\n",
    "import textwrap\n",
    "from collections import defaultdict, deque, Counter\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdbac57",
   "metadata": {},
   "source": [
    "\n",
    "* http://pit-claudel.fr/clement/blog/an-experimental-estimation-of-the-entropy-of-english-in-50-lines-of-python-code/#more-691\n",
    "   \n",
    "* Produces  entropy for model order = 1 for romeo.txt of 3.463 bits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d83796",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def valid_probabilities(distribution):\n",
    "    \"\"\"Arguments:\n",
    "            distribution:  a list of probabilities.\n",
    "       returns:\n",
    "            probabilities, list of valid probabilities. It removes zero values.\n",
    "\n",
    "    All values should be positive.  The sum of the\n",
    "    probabilities should be equal to 1.0 to 2 decimal places. \"\"\"\n",
    "\n",
    "    # Check the probabilities sum to 1.00 to 2 decimal places\n",
    "    if round(sum(distribution), 2) != 1.0:\n",
    "        raise ValueError('Probabilities do not sum to 1')\n",
    "\n",
    "    # Check we have no negative values\n",
    "    if min(distribution) < 0:\n",
    "        raise ValueError('Negative probability')\n",
    "\n",
    "    # Make a list of the probabilities in distribution where\n",
    "    # the probability is greater than zero\n",
    "    probabilities = [p for p in distribution if p > 0]\n",
    "\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5238e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log2(posval):\n",
    "    \"\"\"Arguments:\n",
    "            posval:  a postive number\n",
    "       returns:\n",
    "            result:  float, base 2 log of posval\"\"\"\n",
    "\n",
    "    result = math.log(posval, 2)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7fa18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy_from_probabilities(probabilities):\n",
    "    \"\"\"Arguments:\n",
    "            probabilities:  iterable, a probability distribution\n",
    "       returns:\n",
    "            HX:  float, the entropy of the passed distribution\"\"\"\n",
    "\n",
    "    # Check we have a valid list of probabilities\n",
    "    probabilities = valid_probabilities(probabilities)\n",
    "\n",
    "    # Set entropy count to zero\n",
    "    HX = 0\n",
    "\n",
    "    # Loop over all probabilities and sum the entropy from each (Eq 2.52 P37)\n",
    "    for px in probabilities:\n",
    "        HX = HX + px * log2(1.0/px)\n",
    "\n",
    "    return HX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b0e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy_from_frequencies(frequencies):\n",
    "    \"\"\"Arguments:\n",
    "            frequencies:  iterable, a frequency distribution\n",
    "       returns:\n",
    "            HX:  float, the entropy of the passed distribution\"\"\"\n",
    "\n",
    "    # Transform the frequencies to probabilities. The probability of\n",
    "    # an event is its frequency divided by the sum of all frequencies.\n",
    "\n",
    "    sum_of_frequencies = sum(frequencies)\n",
    "\n",
    "    # Make a list of : the probabilty for each frequency in the\n",
    "    # list of frequencies.\n",
    "\n",
    "    probabilities = [freq / float(sum_of_frequencies) for freq in frequencies]\n",
    "\n",
    "    #\n",
    "    # Now we have a probability distribution, we can find the entropy\n",
    "    #\n",
    "    HX = entropy_from_probabilities(probabilities)\n",
    "\n",
    "    return HX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998183bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy_rate(model):\n",
    "    \"\"\"Calculates the average entropy of the model data.  Does this by\n",
    "    calculating the entropy for each prefix and weighting it by the\n",
    "    frequency with which the prefix appears.\"\"\"\n",
    "\n",
    "    # Initialise counts\n",
    "    total_freq       = 0\n",
    "    weighted_entropy = 0\n",
    "\n",
    "    # Loop for all prefixes\n",
    "    for prefix in model:\n",
    "        # The square brackets denote a list comprehension, which is read from\n",
    "        # left to right.\n",
    "        # In words : \"Make a list of the frequencies for\n",
    "        # each item beginning with prefix.\n",
    "        freqs = [freq for freq in model[prefix].values()]\n",
    "\n",
    "        # Calculate the total frequency of all tokens beginning with\n",
    "        # this prefix\n",
    "        prefix_freq = sum(freqs)\n",
    "\n",
    "        # Increment the total frequency for the whole model\n",
    "        total_freq += prefix_freq\n",
    "\n",
    "        # Calculate the weighted entropy from this prefix.\n",
    "        weighted_entropy += prefix_freq * entropy_from_frequencies(freqs)\n",
    "\n",
    "    # Calculate the average entropy across all the prefix distributions\n",
    "    return weighted_entropy / total_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298b280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tokenize(file_path, tokenizer):\n",
    "    \"\"\"A generator function reads in the file at file_path and uses the passed\n",
    "    tokenizer function to yield tokens.  Generator functions are 'lazy'.  They\n",
    "    only do what work they have to do to yield the next value.  This means\n",
    "    large files are handled with little memory use.\n",
    "\n",
    "       Arguments:\n",
    "            file_path:  string.  The path to the file to read in.\n",
    "            tokenizer: function.  A function to split up the data into\n",
    "                tokens\n",
    "       returns:\n",
    "            token:  the next token in the input\"\"\"\n",
    "\n",
    "    # Open the file for reading.\n",
    "    # break down each line in the file into tokens and yield them one at a\n",
    "    # time.\n",
    "    with codecs.open(file_path, mode=\"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            for token in tokenizer(line.lower().strip()):\n",
    "                yield token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d92a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_space(text):\n",
    "    \"\"\"Appends a space to a string\"\"\"\n",
    "\n",
    "    return text + \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ef77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chars(file_path):\n",
    "    \"\"\"A function to read in data from a file and convert it to\n",
    "    single characters\n",
    "       Arguments:\n",
    "            file_path:  string.  The path to the file to read in.\n",
    "       returns:\n",
    "            token:  the next character in the input\"\"\"\n",
    "\n",
    "    #\n",
    "    # tokenize will open and read file_path.  For each line it will\n",
    "    # append a space and return its contents one character at a time.\n",
    "    #\n",
    "    return tokenize(file_path, append_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04732680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def break_into_words(text):\n",
    "    \"\"\"Function will break the text into words\"\"\"\n",
    "\n",
    "    return re.findall(r\"[a-zA-Z']+\", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8a37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def words(file_path):\n",
    "    \"\"\"A function to read in data from a file and convert it to\n",
    "    words\n",
    "       Arguments:\n",
    "            file_path:  string.  The path to the file to read in.\n",
    "       returns:\n",
    "            token:  the next word in the input\"\"\"\n",
    "\n",
    "    #\n",
    "    # tokenize will open and read file_path.  For each line it will\n",
    "    # break the line into words and return them one at a time.\n",
    "    #\n",
    "    return tokenize(file_path, break_into_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c4fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate(model, length):\n",
    "    \"\"\"A function to create a random sample of length tokens (a token could be\n",
    "    a word or character).\n",
    "    After each iteration we modify the seed/state\n",
    "    by removing the first element of the token and appending a random prefix\n",
    "    from our model based on the new value of state.\"\"\"\n",
    "\n",
    "    text = []\n",
    "\n",
    "    # Pick a random seed as a start point\n",
    "    # e.g. For words with a prefix length of 3, this could be\n",
    "    # \"of each organic\"\n",
    "    prefix = seed(model)\n",
    "\n",
    "    # Loop building up text\n",
    "    for _ in range(length):\n",
    "\n",
    "        # Store the first word/char of the current state\n",
    "        # In our example, would be 'of' for first pass in our example\n",
    "        text.append(prefix[0])\n",
    "\n",
    "        # Pick a new word to append to the current prefix.  The pick function\n",
    "        # looks at the distribution of words/chars starting with prefix\n",
    "        # and picks one at random from the distribution\n",
    "        # For example, or new prefix now drops the 'of' and may become\n",
    "        # \"each organic compound\".\n",
    "        # Then loop with this new prefix.\n",
    "        prefix = prefix[1:] + (pick(model[prefix]), )\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f34585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def pick(counter):\n",
    "    \"\"\"Randomly pick from our counter, weighted by frequency\"\"\"\n",
    "\n",
    "    # Calc size of counter - the total of the frequencies\n",
    "    \n",
    "    size = sum( counter.values() )\n",
    "    if size <= 0:\n",
    "        print( counter )\n",
    "        raise ValueError(\"No frequency values in passed counter\")\n",
    "\n",
    "    # Pick a random element as a target\n",
    "    target = random.randint(1, size)\n",
    "\n",
    "    # Step through the model unitil we reach/pass our target\n",
    "    \n",
    "    cumulative_frequency = 0\n",
    "    \n",
    "    for suffix, frequency in counter.items():\n",
    "        cumulative_frequency += frequency\n",
    "\n",
    "        # If we have reached our target, we are done\n",
    "        if cumulative_frequency >= target:\n",
    "            return suffix\n",
    "\n",
    "    # If we get here we have not picked a suffix\n",
    "    raise ValueError(\"Unable to obtain sample\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77271fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def seed(model):\n",
    "    \"\"\"Randomly pick a prefix from our model, weighted by frequency\"\"\"\n",
    "\n",
    "    # Calc size of model\n",
    "    size = sum([sum(p.values()) for p in model.values()])\n",
    "    if size <= 0:\n",
    "        raise ValueError(\"No frequency values in passed model\")\n",
    "\n",
    "    # Pick a random element\n",
    "    target = random.randint(1, size)\n",
    "\n",
    "    # Step through the model unitil we reach/pass our target\n",
    "    cumulative_frequency = 0\n",
    "    for prefix, possibles in model.items():\n",
    "        cumulative_frequency += sum(possibles.values())\n",
    "\n",
    "        # If we have reached our target, we are done\n",
    "        if cumulative_frequency >= target:\n",
    "            return prefix\n",
    "\n",
    "    # If we get here, we have not found a seed.\n",
    "    raise ValueError(\"Unable to obtain seed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d8030b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def markov_model(stream, model_order):\n",
    "    \"\"\"Function counts the frequency of all distinct strings in the stream\n",
    "    beginning with a prefix of length model_order.  It returns a list of\n",
    "    counters.\"\"\"\n",
    "    # Initialise our Counters.\n",
    "    # model is a dictionary mapping (n?1)-character prefixes to a Counter;\n",
    "    # that Counter maps each possible nth character to the number of times\n",
    "    # this character followed the (n?1)-character prefix.\n",
    "    # For example, model could be\n",
    "    # model = {\n",
    "    #          ('w', 'h'): {'y':25, 'o':12, 'a':16, ...},\n",
    "    #          ('t', 'h'): {'i':15, 'a':18, 'e':34, ...},\n",
    "    #          ...\n",
    "    #         }\n",
    "    # Making model a defaultdict (as opposed a simple dict, like model = {} )\n",
    "    # means that we can just increment its count without first checking\n",
    "    # if a key value exists.\n",
    "\n",
    "    model = defaultdict( Counter )\n",
    "    # Create a queue for appending each token we read.  We are using the deque\n",
    "    # as a pipe of length model_order.\n",
    "    # We add to the pipe by appending to it.\n",
    "    #\n",
    "    # Pipe State     Append\n",
    "    # <empty>        D\n",
    "    # D              O\n",
    "    # DO             G\n",
    "    # DOG            G\n",
    "    # OGG            E\n",
    "    # GGE            D\n",
    "    # GED            etc.\n",
    "\n",
    "    pipe = deque( maxlen=model_order )\n",
    "    \n",
    "    for token in stream:\n",
    "        #\n",
    "        # If the pipe holds model_order characters, then store it contents.\n",
    "        #\n",
    "        if len(pipe) == model_order:\n",
    "\n",
    "            # Convert the pipe contents to something hashable, which can then\n",
    "            # used as a dict key.  Do this with the tuple() function\n",
    "            model[tuple(pipe)][token] += 1\n",
    "\n",
    "        pipe.append(token)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff28bda",
   "metadata": {},
   "source": [
    "\n",
    "## Main Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed5a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_order = 3\n",
    "sample_size = 300\n",
    "    \n",
    "filename = \"romeo.txt\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "410794d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## The entropy of characters\n",
    "\n",
    "model = markov_model( chars(filename), model_order )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316bf58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model order =  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Model order = ', model_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72e2cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter Entropy: 2.0192379863731866  bits/letter.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Letter Entropy:\", entropy_rate( model ), ' bits/letter.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de9890c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model letter output:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Output the a random sample text generated from the input sample\n",
    "# Format it as a block of chars width 70 (default for\n",
    "# textwrap.fill()\n",
    "\n",
    "print('Model letter output:')\n",
    "\n",
    "res = textwrap.fill(  \"\".join( \n",
    "              generate( model, sample_size )\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da9aeeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lone; thus of hat, go, juliet.  nurse ther.  rome sting!  laure, clock\n",
      "and; an [with the and wellords: wherought or son, i'll to be gregory]\n",
      "i do so life as needs! who i down!  lade mour shreath; thy fline othe\n",
      "you; outh, confest, and me, thence thee.  nurse will mustly he's\n",
      "lovert they a fived? the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(  res  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c53b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The entropy of words\n",
    "\n",
    "model = markov_model(   words(filename), model_order   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd6ca78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model order 3\n",
      "Word Entropy = : 0.07689938101662905  bits/word.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print( \"Model order\", model_order )\n",
    "    \n",
    "print(  \"Word Entropy = :\", entropy_rate(model), ' bits/word.'  )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef79967d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model word output:\n",
      "beauty thou art not well sweet sweet sweet nurse tell me what says my\n",
      "love nurse your love says like an honest gentleman where is your\n",
      "mother juliet where is my mother why she is within where should she be\n",
      "how oddly thou repliest 'your love says like an honest gentleman where\n",
      "is your mother juliet where is my page go villain fetch a surgeon exit\n",
      "page romeo courage man the hurt cannot be much mercutio no 'tis not so\n",
      "deep as a well nor so wide as a church door but 'tis enough 'twill\n",
      "serve ask for me to\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Output the a random sample text generated from the input sample\n",
    "# Format it as a block of chars width 70 (default for\n",
    "# textwrap.fill()\n",
    "\n",
    "print( 'Model word output:' )\n",
    "\n",
    "other_res = textwrap.fill(   \n",
    "                \" \".join(   generate(model, 100)    )  \n",
    ")\n",
    "\n",
    "print( other_res )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf41071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14912da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06eaeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d06ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd2260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c56d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62000afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576fe8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0f7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
